{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91u4SmWsmSoN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from prophet import Prophet\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "import numpy as np\n",
        "import cmdstanpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('/content/dataset_25.xlsx')\n",
        "print(df.columns)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "rimEab5ZmZpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "lZEUC4rtnsx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "1Gx2Nqqdn6d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"date\"] = pd.to_datetime(df[\"date\"])"
      ],
      "metadata": {
        "id": "yCZII2i9oJmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combination of attributes\n",
        "df['vol'] = df['vol'] / 15\n",
        "# ou, se quiser renomear a coluna depois\n",
        "df.rename(columns={'vol': 'qtd_vendida'}, inplace=True)\n",
        "\n",
        "# Ordem cronológica da série\n",
        "df = df.sort_values('date').reset_index(drop=True)\n",
        "\n",
        "# View combination\n",
        "df.head()"
      ],
      "metadata": {
        "id": "e8P6DinFuzpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identificando se existe Datas Faltantes\n",
        "\n",
        "# Gerando todas as datas do intervalo esperado\n",
        "datas_completas = pd.date_range(start=df['date'].min(), end=df['date'].max(), freq='D')\n",
        "\n",
        "# Verificando quais datas estão faltando\n",
        "datas_faltando  = datas_completas.difference(df['date'])\n",
        "\n",
        "datas_faltando"
      ],
      "metadata": {
        "id": "9eV_uNUYoUU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_datas_completas = pd.DataFrame(datas_completas, columns=[\"date\"])\n"
      ],
      "metadata": {
        "id": "2Dhsy6g8oYEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_vendas_diarias =  df.groupby('date')['qtd_vendida'].sum().reset_index()\n",
        "\n",
        "\n",
        "df_vendas_diarias"
      ],
      "metadata": {
        "id": "QHWWlY_QobqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mesclado o DataFrame de datas completas com o DataFrame de vendas diárias agregadas. Usamos um left merge para manter todas as datas.\n",
        "# O fillna(0) preenche os dias que não tinham vendas (datas faltantes) com 0.\n",
        "# Renomeado as colunas para clareza. df_completo é a série temporal principal que vamos analisar e modelar.\n",
        "\n",
        "df_completo = df_datas_completas.merge(df_vendas_diarias, on=\"date\", how=\"left\").fillna(0)\n",
        "# Renomeia as colunas date para data e money para qtd_vendida, já que a coluna money foi agregada por quantidade (count())\n",
        "df_completo.columns = [\"data\", \"qtd_vendida\"]\n",
        "df_completo"
      ],
      "metadata": {
        "id": "5lqQat8gpFtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_zero = df_completo[df_completo['qtd_vendida'] == 0]\n",
        "df_zero"
      ],
      "metadata": {
        "id": "_40Jq6DKpL_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformando a coluna 'data' em índice do DataFrame\n",
        "df_index_data = df_completo.set_index('data')\n",
        "\n",
        "# Criando uma série (Series) com apenas os valores da coluna 'qtd_vendida'\n",
        "serie_vendas = df_index_data['qtd_vendida']\n",
        "\n",
        "# Calculando Media Movel Para detectar tendências mensais (entender a tendência real de crescimento ou queda)\n",
        "media_movel = serie_vendas.rolling(window=30).mean()\n",
        "\n",
        "#Calculando Desvio Padrão Movel\n",
        "desvio_movel = serie_vendas.rolling(window=30).std()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.plot(serie_vendas, label='Vendas Diárias')\n",
        "plt.plot(media_movel, label='Média Móvel (30 dias)', linestyle='--')\n",
        "plt.plot(desvio_movel, label='Desvio Padrão Móvel (30 dias)', linestyle=':')\n",
        "plt.xlabel('Data')\n",
        "plt.ylabel('Qtd de Cafés Vendidos')\n",
        "plt.title('Análise de Vendas')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P0YvHSiqpRIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decomposição da série temporal\n",
        "decomposicao = seasonal_decompose(serie_vendas, model='additive', period=7)\n",
        "\n",
        "# Plotar os componentes\n",
        "\n",
        "# Gráfico manual com maior tamanho\n",
        "fig, axs = plt.subplots(4, 1, figsize=(14, 10), sharex=True)\n",
        "\n",
        "axs[0].plot(decomposicao.observed, label='Original')\n",
        "axs[0].set_ylabel('Observado')\n",
        "axs[0].legend()\n",
        "\n",
        "axs[1].plot(decomposicao.trend, label='Trend', color='orange')\n",
        "axs[1].set_ylabel('Tendência')\n",
        "axs[1].legend()\n",
        "\n",
        "axs[2].plot(decomposicao.seasonal, label='Seasonal', color='green')\n",
        "axs[2].set_ylabel('Sazonalidade')\n",
        "axs[2].legend()\n",
        "\n",
        "axs[3].plot(decomposicao.resid, label='Residual', color='red')\n",
        "axs[3].set_ylabel('Residual')\n",
        "axs[3].legend()\n",
        "\n",
        "plt.suptitle('Decomposição da Série Temporal', fontsize=16)\n",
        "plt.xlabel('Data')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uvCygq1SpY0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparação dos dados para o Prophet\n",
        "df_prophet = serie_vendas.reset_index()\n",
        "df_prophet.columns = ['ds', 'y']\n",
        "df_prophet.head()"
      ],
      "metadata": {
        "id": "xkzHUOLCpgKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função treinar_e_prever_prophet()\n",
        "\n",
        "def treinar_e_prever_prophet(df_treino, df_teste):\n",
        "    modelo = Prophet()\n",
        "    modelo.fit(df_treino)\n",
        "    futuro = modelo.make_future_dataframe(periods=len(df_teste))\n",
        "    previsao = modelo.predict(futuro)\n",
        "    datas = df_teste['ds'].tolist()\n",
        "    previsao_filtrada = previsao[previsao['ds'].isin(datas)]\n",
        "    previsao_filtrada = previsao_filtrada.set_index('ds').loc[datas].reset_index()\n",
        "    return previsao_filtrada"
      ],
      "metadata": {
        "id": "YpW_LKpIpkuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validação Cruzada Temporal com Métricas\n",
        "\n",
        "# Parâmetros da validação cruzada\n",
        "tamanho_inicial_treino = int(len(df_prophet) * 0.6)\n",
        "horizonte_previsao = int(len(df_prophet) * 0.1)\n",
        "\n",
        "metricas_prophet = []\n",
        "\n",
        "# Validação cruzada temporal\n",
        "for i in range(tamanho_inicial_treino, len(df_prophet) - horizonte_previsao, horizonte_previsao):\n",
        "    df_treino = df_prophet.iloc[:i]\n",
        "    df_teste = df_prophet.iloc[i:i + horizonte_previsao]\n",
        "\n",
        "    previsao = treinar_e_prever_prophet(df_treino, df_teste)\n",
        "\n",
        "    mae = mean_absolute_error(df_teste['y'], previsao['yhat'])\n",
        "    rmse = np.sqrt(mean_squared_error(df_teste['y'], previsao['yhat']))\n",
        "\n",
        "    metricas_prophet.append({'mae': mae, 'rmse': rmse})\n",
        "    print(f\"Iteração {len(metricas_prophet)} - MAE: {mae:.2f}, RMSE: {rmse:.2f}\")\n",
        "\n",
        "mae_medio = np.mean([m['mae'] for m in metricas_prophet])\n",
        "rmse_medio = np.mean([m['rmse'] for m in metricas_prophet])\n",
        "\n",
        "print(\"\\nMétricas Médias com Validação Cruzada Temporal para Prophet:\")\n",
        "print(f\"MAE Médio: {mae_medio:.2f}\")\n",
        "print(f\"RMSE Médio: {rmse_medio:.2f}\")"
      ],
      "metadata": {
        "id": "Oa75GYoMpqfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualização das Previsões por Fold\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(df_prophet['ds'], df_prophet['y'], label='Real', color='black')\n",
        "\n",
        "for i in range(len(metricas_prophet)):\n",
        "    inicio = tamanho_inicial_treino + i * horizonte_previsao\n",
        "    fim = inicio + horizonte_previsao\n",
        "    if fim > len(df_prophet):\n",
        "        break\n",
        "    df_treino = df_prophet.iloc[:inicio]\n",
        "    df_teste = df_prophet.iloc[inicio:fim]\n",
        "\n",
        "    previsao = treinar_e_prever_prophet(df_treino, df_teste)\n",
        "\n",
        "    plt.plot(df_teste['ds'], previsao['yhat'], label=f'Previsão Fold {i+1}', linestyle='--')\n",
        "\n",
        "plt.title('Validação Cruzada Temporal - Previsões Prophet')\n",
        "plt.xlabel('Data')\n",
        "plt.ylabel('Receita prevista')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MkxZ-Cn_pz_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste Aumentado de Dickey-Fuller para verificar estacionaridade\n",
        "resultado_adf = adfuller(serie_vendas)\n",
        "\n",
        "print(f'Estatística ADF: {resultado_adf[0]}')\n",
        "print(f'Valor-p: {resultado_adf[1]}')\n",
        "print('Valores Críticos:')\n",
        "for chave, valor in resultado_adf[4].items():\n",
        "    print(f'\\t{chave}: {valor}')\n",
        "\n",
        "if resultado_adf[1] <= 0.05:\n",
        "    print(\"\\nA série é estacionária (rejeitamos a hipótese nula).\")\n",
        "else:\n",
        "    print(\"\\nA série NÃO é estacionária (não rejeitamos a hipótese nula).\")"
      ],
      "metadata": {
        "id": "WG5SnmAcp-Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "# Plotagem do ACF para a série diferenciada\n",
        "plt.figure(figsize=(12, 6))\n",
        "plot_acf(serie_vendas, lags=40, ax=plt.gca())\n",
        "plt.title('Função de Autocorrelação (ACF) - Série Diferenciada')\n",
        "plt.xlabel('Defasagem')\n",
        "plt.ylabel('Autocorrelação')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plotagem do PACF para a série diferenciada\n",
        "plt.figure(figsize=(12, 6))\n",
        "plot_pacf(serie_vendas, lags=40, ax=plt.gca())\n",
        "plt.title('Função de Autocorrelação Parcial (PACF) - Série Diferenciada')\n",
        "plt.xlabel('Defasagem')\n",
        "plt.ylabel('Autocorrelação Parcial')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "08eet-ikqEBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para treinar e prever com ARIMA\n",
        "\n",
        "def treinar_e_prever_arima(serie_treino, serie_teste, order):\n",
        "    # O modelo ARIMA assume que a série de entrada é a série original\n",
        "    # e o parâmetro 'order' lida com a diferenciação\n",
        "    modelo = ARIMA(serie_treino, order=order)\n",
        "    resultado = modelo.fit()\n",
        "\n",
        "    # O método forecast() prevê para o número especificado de passos à frente\n",
        "    previsao = resultado.forecast(steps=len(serie_teste))\n",
        "\n",
        "    # Retornar um DataFrame similar ao do Prophet para facilitar a comparação\n",
        "    previsao_df = pd.DataFrame({\n",
        "        'ds': serie_teste.index,\n",
        "        'yhat': previsao.values # previsao.values contém os valores previstos\n",
        "    })\n",
        "    return previsao_df"
      ],
      "metadata": {
        "id": "bmp0sP0YqJ-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordem do modelo ARIMA com base na análise de ACF/PACF e ADF\n",
        "ordem_arima_definida = (1, 1, 1)\n",
        "\n",
        "# Validação Cruzada Temporal com Métricas para ARIMA\n",
        "\n",
        "# Parâmetros da validação cruzada\n",
        "tamanho_inicial_treino = int(len(serie_vendas) * 0.6) # Usando o tamanho da série original\n",
        "horizonte_previsao = int(len(serie_vendas) * 0.1)   # Usando o tamanho da série original\n",
        "\n",
        "metricas_arima = [] # Lista para as métricas do ARIMA\n",
        "\n",
        "# Validação cruzada temporal\n",
        "# Loop sobre os índices da série original\n",
        "for i in range(tamanho_inicial_treino, len(serie_vendas) - horizonte_previsao, horizonte_previsao):\n",
        "\n",
        "    # Para o ARIMA, precisamos da série temporal na escala original (objeto Series do pandas)\n",
        "    # O objeto 'serie' já está com o índice de data e valores agregados diariamente\n",
        "    serie_treino_arima = serie_vendas.iloc[:i]\n",
        "    serie_teste_arima = serie_vendas.iloc[i:i + horizonte_previsao]\n",
        "\n",
        "    # Previsão com ARIMA\n",
        "    try:\n",
        "        previsao_arima = treinar_e_prever_arima(serie_treino_arima, serie_teste_arima, ordem_arima_definida)\n",
        "        # Comparar com os valores reais da série_teste_arima (objeto Series)\n",
        "        mae_arima = mean_absolute_error(serie_teste_arima.values, previsao_arima['yhat'])\n",
        "        rmse_arima = np.sqrt(mean_squared_error(serie_teste_arima.values, previsao_arima['yhat']))\n",
        "        metricas_arima.append({'mae': mae_arima, 'rmse': rmse_arima})\n",
        "        print(f\"Iteração {len(metricas_arima)} - ARIMA (MAE: {mae_arima:.2f}, RMSE: {rmse_arima:.2f})\")\n",
        "    except Exception as e:\n",
        "        # Tratar possíveis erros durante o treinamento do ARIMA (pode acontecer com certas ordens ou dados)\n",
        "        print(f\"Erro ao treinar ou prever com ARIMA na iteração {len(metricas_arima) + 1}: {e}\")\n",
        "        metricas_arima.append({'mae': np.nan, 'rmse': np.nan}) # Adicionar NaN para não quebrar o cálculo da média\n",
        "\n",
        "# Cálculo das métricas médias\n",
        "mae_medio_arima = np.nanmean([m['mae'] for m in metricas_arima]) # Usar nanmean para ignorar NaNs se houver erros\n",
        "rmse_medio_arima = np.nanmean([m['rmse'] for m in metricas_arima])\n",
        "\n",
        "print(\"\\nMétricas Médias com Validação Cruzada Temporal para ARIMA:\")\n",
        "print(f\"MAE Médio: {mae_medio_arima:.2f}\")\n",
        "print(f\"RMSE Médio: {rmse_medio_arima:.2f}\")"
      ],
      "metadata": {
        "id": "wD8OeW_BqOOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualização das Previsões por Fold para ARIMA\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "# Plotar a série real completa para referência\n",
        "plt.plot(serie_vendas.index, serie_vendas.values, label='Real', color='black')\n",
        "\n",
        "# Parâmetros da validação cruzada (certifique-se de que são os mesmos usados na avaliação)\n",
        "tamanho_inicial_treino = int(len(serie_vendas) * 0.6)\n",
        "horizonte_previsao = int(len(serie_vendas) * 0.1)\n",
        "ordem_arima_definida = (1, 1, 1) # Use a ordem que você definiu\n",
        "\n",
        "# Loop para gerar previsões em cada fold e plotar\n",
        "# O loop itera sobre os índices da série original\n",
        "fold_count = 0 # Contador para o número do fold\n",
        "for i in range(tamanho_inicial_treino, len(serie_vendas) - horizonte_previsao, horizonte_previsao):\n",
        "    fold_count += 1\n",
        "    inicio = i\n",
        "    fim = i + horizonte_previsao\n",
        "\n",
        "    # Certificar-se de que o fold de teste não ultrapassa o tamanho da série\n",
        "    if fim > len(serie_vendas):\n",
        "        break\n",
        "\n",
        "    # Extrair dados de treino e teste para o fold atual\n",
        "    serie_treino_arima = serie_vendas.iloc[:inicio]\n",
        "    serie_teste_arima = serie_vendas.iloc[inicio:fim]\n",
        "\n",
        "    # Gerar previsões para o fold de teste\n",
        "    try:\n",
        "        previsao_arima = treinar_e_prever_arima(serie_treino_arima, serie_teste_arima, ordem_arima_definida)\n",
        "\n",
        "        # Plotar as previsões do ARIMA para o fold atual\n",
        "        # Use um rótulo único para cada fold\n",
        "        plt.plot(previsao_arima['ds'], previsao_arima['yhat'], label=f'Previsão ARIMA Fold {fold_count}', linestyle='--')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao gerar previsão para plotagem do ARIMA no Fold {fold_count}: {e}\")\n",
        "        # Se ocorrer um erro, não plotamos este fold\n",
        "\n",
        "plt.title('Validação Cruzada Temporal - Previsões ARIMA')\n",
        "plt.xlabel('Data')\n",
        "plt.ylabel('Receita prevista')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YRCFjNj7qWEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparação de Desempenho - Previsão de 1 Passo\n",
        "\n",
        "# Definir o tamanho inicial do treino (pode ser o mesmo da validação cruzada ou um valor fixo)\n",
        "tamanho_inicial_treino_1_passo = int(len(serie_vendas) * 0.6) # Ou outro valor apropriado\n",
        "\n",
        "previsoes_reais_1_passo = []\n",
        "previsoes_prophet_1_passo = []\n",
        "previsoes_arima_1_passo = []\n",
        "\n",
        "# Loop para previsão de 1 passo\n",
        "# Começa onde termina o tamanho inicial do treino\n",
        "for i in range(tamanho_inicial_treino_1_passo, len(serie_vendas)):\n",
        "\n",
        "    # Obter dados de treino para o passo atual\n",
        "    df_treino_prophet = df_prophet.iloc[:i]\n",
        "    serie_treino_arima = serie_vendas.iloc[:i]\n",
        "\n",
        "    # Obter o valor real do próximo passo\n",
        "    if i < len(serie_vendas):\n",
        "        valor_real_proximo_passo = serie_vendas.iloc[i]\n",
        "        data_proximo_passo = serie_vendas.index[i]\n",
        "    else:\n",
        "        # Isso só aconteceria se o loop chegasse ao fim da série\n",
        "        break # Sair do loop se não houver mais dados reais para comparar\n",
        "\n",
        "    # Armazenar o valor real\n",
        "    previsoes_reais_1_passo.append({'ds': data_proximo_passo, 'y': valor_real_proximo_passo})\n",
        "\n",
        "    # Prever 1 passo à frente com Prophet\n",
        "    try:\n",
        "        # Prophet precisa de um DataFrame de futuro com a data do próximo passo\n",
        "        futuro_prophet_1_passo = pd.DataFrame({'ds': [data_proximo_passo]})\n",
        "        previsao_prophet = Prophet().fit(df_treino_prophet).predict(futuro_prophet_1_passo)\n",
        "        previsoes_prophet_1_passo.append({'ds': data_proximo_passo, 'yhat': previsao_prophet['yhat'].iloc[0]})\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao prever 1 passo com Prophet na data {data_proximo_passo}: {e}\")\n",
        "        previsoes_prophet_1_passo.append({'ds': data_proximo_passo, 'yhat': np.nan})\n",
        "\n",
        "\n",
        "    # Prever 1 passo à frente com ARIMA\n",
        "    try:\n",
        "        # ARIMA prevê o número especificado de passos à frente (aqui 1)\n",
        "        modelo_arima_1_passo = ARIMA(serie_treino_arima, order=ordem_arima_definida)\n",
        "        resultado_arima_1_passo = modelo_arima_1_passo.fit()\n",
        "        previsao_arima = resultado_arima_1_passo.forecast(steps=1)\n",
        "        previsoes_arima_1_passo.append({'ds': data_proximo_passo, 'yhat': previsao_arima.iloc[0]}) # ARIMA forecast retorna uma Series ou array\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao prever 1 passo com ARIMA na data {data_proximo_passo}: {e}\")\n",
        "        previsoes_arima_1_passo.append({'ds': data_proximo_passo, 'yhat': np.nan})\n",
        "\n",
        "\n",
        "# Converter listas de previsões para DataFrames para facilitar o cálculo de métricas\n",
        "df_reais_1_passo = pd.DataFrame(previsoes_reais_1_passo).set_index('ds')\n",
        "df_prophet_1_passo = pd.DataFrame(previsoes_prophet_1_passo).set_index('ds')\n",
        "df_arima_1_passo = pd.DataFrame(previsoes_arima_1_passo).set_index('ds')\n",
        "\n",
        "# Juntar os DataFrames para garantir que as comparações sejam feitas nas mesmas datas\n",
        "df_comparacao_1_passo = df_reais_1_passo.join(df_prophet_1_passo, rsuffix='_prophet').join(df_arima_1_passo, rsuffix='_arima').dropna()\n",
        "\n",
        "\n",
        "# Calcular métricas de avaliação para previsão de 1 passo\n",
        "mae_prophet_1_passo = mean_absolute_error(df_comparacao_1_passo['y'], df_comparacao_1_passo['yhat'])\n",
        "rmse_prophet_1_passo = np.sqrt(mean_squared_error(df_comparacao_1_passo['y'], df_comparacao_1_passo['yhat']))\n",
        "\n",
        "mae_arima_1_passo = mean_absolute_error(df_comparacao_1_passo['y'], df_comparacao_1_passo['yhat_arima']) # Usar 'yhat_arima' após o join\n",
        "rmse_arima_1_passo = np.sqrt(mean_squared_error(df_comparacao_1_passo['y'], df_comparacao_1_passo['yhat_arima']))\n",
        "\n",
        "\n",
        "print(\"\\nMétricas de Desempenho - Previsão de 1 Passo:\")\n",
        "print(\"Prophet:\")\n",
        "print(f\"MAE: {mae_prophet_1_passo:.2f}\")\n",
        "print(f\"RMSE: {rmse_prophet_1_passo:.2f}\")\n",
        "print(\"\\nARIMA:\")\n",
        "print(f\"MAE: {mae_arima_1_passo:.2f}\")\n",
        "print(f\"RMSE: {rmse_arima_1_passo:.2f}\")\n",
        "\n",
        "# Opcional: Visualizar as previsões de 1 passo\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(df_comparacao_1_passo.index, df_comparacao_1_passo['y'], label='Real', color='black')\n",
        "plt.plot(df_comparacao_1_passo.index, df_comparacao_1_passo['yhat'], label='Previsão Prophet (1 passo)', linestyle='--')\n",
        "plt.plot(df_comparacao_1_passo.index, df_comparacao_1_passo['yhat_arima'], label='Previsão ARIMA (1 passo)', linestyle='--')\n",
        "plt.title('Comparação de Previsões (1 Passo)')\n",
        "plt.xlabel('Data')\n",
        "plt.ylabel('Qtd')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iCVzcXM7qjDG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}